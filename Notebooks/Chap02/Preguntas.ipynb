{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problema 2.1** Para descender en la función de pérdida (ecuación 2.5), medimos su gradiente con respecto a los parámetros $\\phi_0$ y $\\phi_1$. Calcula las expresiones para las pendientes $\\frac{\\partial L}{\\partial \\phi_0}$ y $\\frac{\\partial L}{\\partial \\phi_1}$.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de pérdida es:\n",
    "\n",
    "$$\n",
    "L[\\phi] = \\sum_{i=1}^{I} \\left( f[x_i, \\phi] - y_i \\right)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\sum_{i=1}^{I} \\left( \\phi_0 + \\phi_1 x_i - y_i \\right)^2.\n",
    "\\quad \\quad \\quad \\quad (2.5)\n",
    "$$\n",
    "\n",
    "\n",
    "Para calcular esas derivadas parciales tenemos que realizar regla de la cadena:\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial g(h(\\phi_0))}{\\partial \\phi_0} = g'(h(\\phi_0)) * h'(\\phi_0)\n",
    " $$\n",
    "\n",
    "- Función externa es $g(u) = u ^2 $ así su derivada es $g'(u)= 2u$\n",
    "- Función interna es $h_i(\\phi_0, \\phi_1) = \\phi_0 + \\phi_1 x_i - y_i $ y sus derivada respectivamente es:\n",
    " $$\\frac{\\partial h_i}{\\partial \\phi_0}  = 1 $$\n",
    "  $$\\frac{\\partial h_i}{\\partial \\phi_1}  = x $$\n",
    "\n",
    "Calculemos la derivada parcial de cada una:\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial g(h(\\phi_0))}{\\partial \\phi_0} = g'(h(\\phi_0)) * h'(\\phi_0)\n",
    " $$\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial g(h(\\phi_0))}{\\partial \\phi_0} = 2 (\\phi_0 + \\phi_1 x_i - y_i) * 1\n",
    " $$ \n",
    "\n",
    "Luego para la otra derivada es\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial g(h(\\phi_1))}{\\partial \\phi_1} = g'(h(\\phi_1)) * h'(\\phi_1)\n",
    " $$\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial g(h(\\phi_0))}{\\partial \\phi_0} = 2 (\\phi_0 + \\phi_1 x_i - y_i) * x\n",
    " $$\n",
    "\n",
    "Finalmente tenemos:\n",
    "\n",
    "- Para $\\phi_0 $:\n",
    "\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial \\phi_0} = 2 \\sum_{i=1}^{I} (\\phi_0 + \\phi_1 x_i - y_i).\n",
    "  $$\n",
    "\n",
    "- Para $\\phi_1 $:\n",
    "\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial \\phi_1} = 2 \\sum_{i=1}^{I} (\\phi_0 + \\phi_1 x_i - y_i) x_i.\n",
    "  $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Problema 2.2** Muestra que podemos encontrar el mínimo de la función de pérdida en forma cerrada estableciendo la expresión para las derivadas del problema 2.1 igual a cero y resolviendo para $\\phi_0$ y $\\phi_1$. Nota que esto funciona para regresión lineal, pero no para modelos más complejos; por esta razón utilizamos métodos iterativos de ajuste de modelos como el descenso de gradiente (figura 2.4).  \n",
    "\n",
    "\n",
    "- Para $\\phi_0 $:\n",
    "\n",
    "  $$\n",
    "  0 = 2 \\sum_{i=1}^{I} (\\phi_0 + \\phi_1 x_i - y_i).\\\\\n",
    "  \n",
    "  0 = \\sum_{i=1}^{I} \\phi_0 + \\sum_{i=1}^I \\phi_1 x_i - y_i \\\\\n",
    "\n",
    "  0 = I * \\phi_0  + \\sum_{i=1}^I \\phi_1 x_i - y_i \\\\\n",
    "\n",
    "  \\phi_0 =  - \\sum_{i=1}^I \\phi_1 x_i - y_i * \\frac{1}{I}\n",
    "  $$\n",
    "\n",
    "\n",
    "- Para $\\phi_1 $:\n",
    "\n",
    "  $$\n",
    "  0 = 2 \\sum_{i=1}^{I} (\\phi_0 + \\phi_1 x_i - y_i) x_i. \\\\\n",
    "\n",
    "  0 = \\sum_{i=i}^{I} \\phi_0 * x_i + \\sum_{i=i}^{I} \\phi_1 * x_i^2  - \\sum_{i=i}^{I} y_i* x_i \\\\\n",
    "\n",
    "  \\phi_1 * \\sum_{i=i}^{I}  x_i^2 = -  \\sum_{i=i}^{I} \\phi_0 * x_i  +  \\sum_{i=i}^{I} y_i* x_i \\\\\n",
    "\n",
    "  \\phi_1 = \\frac{-  \\sum_{i=i}^{I} \\phi_0 * x_i  +  \\sum_{i=i}^{I} y_i* x_i}{\\sum_{i=i}^{I}  x_i^2}\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Problema 2.3** Considera reformular la regresión lineal como un modelo generativo, de modo que tenemos $x = g(y, \\phi) = \\phi_0 + \\phi_1 y$. ¿Cuál es la nueva función de pérdida? Encuentra una expresión para la función inversa $y = g^{-1}(x, \\phi)$ que usaríamos para realizar inferencia. ¿Este modelo hará las mismas predicciones que la versión discriminativa para un conjunto de datos de entrenamiento $\\{x_i, y_i\\}$? Una forma de comprobarlo es escribir código que ajuste una línea a tres puntos de datos usando ambos métodos y ver si el resultado es el mismo.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problema 2.3**  \n",
    "- ¿Cuál es la nueva función de perdida?\n",
    "\n",
    "$L = \\sum_{i = 1}  (g(y, \\phi) - x) ^2 =\\sum_{i =1}  (\\phi_0 + \\phi_1 y_i - x_i) ^2  $\n",
    "- Encuentra una expresión para la función inversa  $y = g^{-1}(x, \\phi)$ que usaríamos para realizar inferencia.\n",
    "\n",
    "$x  = \\phi_0 + \\phi_1 y $ \n",
    "\n",
    "$y = (x -\\phi_0) \\frac{1}{\\phi_1} = g^{-1}(x, \\phi) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preguntas Adicionales \n",
    "\n",
    "- **Que es la inversa de una regresión?**\n",
    "\n",
    "- Tenemos las siguientes ideas, la regresión es el proceso de tener un conjunto mas grande de nuestra muestra $y$. Ya que vamos a tener un pequeño conjunto\n",
    "$y = \\{ y_0, y_1, ..., y_n \\} $, yo me imagino, que con la inversa yo ya tengo todas las muestras. Ahora la variable $x$ que era la independiente, la cual \n",
    "ayudaba a modelar nuestro fenomeno, me pregunto, que significa ahora, $x = g^{-1}(y, \\phi) = \\frac{1}{\\phi_1 } (-\\phi_0 + y)$. Supongo que lo que tendría sentido es que no tengamos ese conjunto $y$ y lo que tengamos es algunos valores de x que seria otras muestras. Pero, entonces no entiendo como es un **Modelo Generativo**.\n",
    "\n",
    "- **Que es una regresión**: es el proceso de ajustar una función a un conjunto de datos y modelar la relación entre las variables dependientes con las independientes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
